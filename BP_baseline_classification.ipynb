{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zp7SDQtQ6HKm"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1Po8gSDI6NC7"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "from torch.optim import Adam\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import Compose, ToTensor, Normalize, Lambda\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "import altair as alt\n",
        "alt.data_transformers.disable_max_rows()\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def plot_tsne(tsne_xy, dataloader, num_points=1000, darkmode=True):\n",
        "    # import IPython # Try to automatically detect darkmode - colab is blocking my DOM request\n",
        "    # # html[theme=dark]\n",
        "    # js_code = r'document.documentElement.getAttribute(\"theme\");'\n",
        "    # display(IPython.display.Javascript(js_code))\n",
        "\n",
        "    images, labels = zip(*[(x[0].numpy()[0,:,:,None], x[1]) for x in dataloader.dataset])\n",
        "\n",
        "    num_points = min(num_points, len(labels))\n",
        "    data = pd.DataFrame({'x':tsne_xy[:, 0], 'y':tsne_xy[:, 1], 'label':labels,\n",
        "                        'image': images})\n",
        "    data = data.sample(n=num_points, replace=False)\n",
        "\n",
        "    alt.renderers.set_embed_options(theme='dark' if darkmode else 'light')\n",
        "    selection = alt.selection_single(on='mouseover', clear='false', nearest=True,\n",
        "                                    init={'x':data['x'][data.index[0]], 'y':data['y'][data.index[0]]})\n",
        "    scatter = alt.Chart(data).mark_circle().encode(\n",
        "        alt.X('x:N',axis=None),\n",
        "        alt.Y('y:N',axis=None),\n",
        "        color=alt.condition(selection,\n",
        "                            alt.value('lightgray'),\n",
        "                            alt.Color('label:N')),\n",
        "        # shape= alt.Shape('label:N', condition=selection,scale=alt.Scale(range=['circle','diamond'])),\n",
        "        size=alt.value(100),\n",
        "        tooltip='label:N'\n",
        "    ).add_selection(\n",
        "        selection\n",
        "    ).properties(\n",
        "        width=400,\n",
        "        height=400\n",
        "    )\n",
        "\n",
        "    digit  = alt.Chart(data).transform_filter(\n",
        "        selection\n",
        "    ).transform_window(\n",
        "        index='count()'           # number each of the images\n",
        "    ).transform_flatten(\n",
        "        ['image']                 # extract rows from each image\n",
        "    ).transform_window(\n",
        "        row='count()',            # number the rows...\n",
        "        groupby=['index']         # ...within each image\n",
        "    ).transform_flatten(\n",
        "        ['image']                 # extract the values from each row\n",
        "    ).transform_window(\n",
        "        column='count()',         # number the columns...\n",
        "        groupby=['index', 'row']  # ...within each row & image\n",
        "    ).mark_rect(stroke='black',strokeWidth=0).encode(\n",
        "        alt.X('column:O', axis=None),\n",
        "        alt.Y('row:O', axis=None),\n",
        "        alt.Color('image:Q',sort='descending',\n",
        "            scale=alt.Scale(scheme=alt.SchemeParams('darkblue' if darkmode else 'lightgreyteal',\n",
        "                            extent=[1, 0]),\n",
        "\n",
        "            ),\n",
        "            legend=None\n",
        "        ),\n",
        "    ).properties(\n",
        "        width=400,\n",
        "        height=400,\n",
        "    )\n",
        "\n",
        "    return scatter | digit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qU_peqZP6L7l"
      },
      "source": [
        "# Load Data Outcome Variables:\n",
        "- **train_loader**\n",
        "- **test_loader**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9pTqUQL6baq",
        "outputId": "657e839f-c73b-4fdf-be0b-e2e233768299"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 30982373.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 1996797.06it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 3209846.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 3220170.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def MNIST_loaders(train_batch_size=50000, test_batch_size=10000):\n",
        "\n",
        "    transform = Compose([\n",
        "        ToTensor(),\n",
        "        Normalize((0.1307,), (0.3081,)),\n",
        "        Lambda(lambda x: torch.flatten(x))])\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        MNIST('./data/', train=True,\n",
        "              download=True,\n",
        "              transform=transform),\n",
        "        batch_size=train_batch_size, shuffle=True)\n",
        "\n",
        "    test_loader = DataLoader(\n",
        "        MNIST('./data/', train=False,\n",
        "              download=True,\n",
        "              transform=transform),\n",
        "        batch_size=test_batch_size, shuffle=False)\n",
        "\n",
        "    return train_loader, test_loader\n",
        "\n",
        "torch.manual_seed(1234)\n",
        "train_loader, test_loader = MNIST_loaders()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BP Baseline"
      ],
      "metadata": {
        "id": "Crce4wlQFL5K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = next(iter(train_loader))\n",
        "x_te, y_te = next(iter(test_loader))"
      ],
      "metadata": {
        "id": "3I0_OVbj20gQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "yYUM24PnksWz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b37b1c9a-03d4-4357-f688-94704114a227"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BPNet(\n",
            "  (model_linear): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=500, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=500, out_features=300, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=300, out_features=300, bias=True)\n",
            "    (5): ReLU()\n",
            "    (6): Linear(in_features=300, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "\n",
        "class BPNet(torch.nn.Module):\n",
        "    def __init__(self, dims, epoch):\n",
        "        super(BPNet, self).__init__()\n",
        "        self.model_linear = nn.Sequential(nn.Linear(dims[0],dims[1]), nn.ReLU(),\n",
        "                                          nn.Linear(dims[1],dims[2]), nn.ReLU(),\n",
        "                                          nn.Linear(dims[2],dims[3]), nn.ReLU(),\n",
        "                                          nn.Linear(dims[3],dims[4]))\n",
        "        self.opt = torch.optim.Adam(self.model_linear.parameters(), lr=0.01)\n",
        "        # self.opt = torch.optim.SGD(self.model_linear.parameters(), lr=0.01)\n",
        "\n",
        "        self.epochs = epoch\n",
        "        self.loss_func = F.cross_entropy\n",
        "        self.batch_size = 240\n",
        "\n",
        "    def train(self, x, y):\n",
        "        batch_size = self.batch_size\n",
        "        model_linear = self.model_linear\n",
        "        loss_func = self.loss_func\n",
        "        opt = self.opt\n",
        "        for epoch in range(self.epochs):\n",
        "            for i in tqdm(range((x.shape[0]-1)//batch_size + 1)):\n",
        "                start_i = i * batch_size\n",
        "                end_i = start_i + batch_size\n",
        "                xb = x[start_i:end_i]\n",
        "                yb = y[start_i:end_i]\n",
        "                pred = model_linear(xb)\n",
        "                loss = loss_func(pred, yb)\n",
        "                loss.backward()\n",
        "                opt.step() # Updating weights.\n",
        "                opt.zero_grad()\n",
        "\n",
        "    def acc(self, x, y):\n",
        "        y_pred = self.model_linear(x)\n",
        "        return (torch.argmax(y_pred, dim=1) == y).float().mean()\n",
        "net_BP = BPNet([784, 500, 300, 300, 10], 1)\n",
        "print(net_BP)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc_trs, acc_tes = [], []\n",
        "for i in range(5):\n",
        "    net_BP = BPNet([784, 500, 300, 300, 10], 1)\n",
        "    net_BP.train(x, F.one_hot(y).float())\n",
        "    acc_trs.append(net_BP.acc(x, y).item())\n",
        "    acc_tes.append(net_BP.acc(x_te, y_te).item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKEnB6M902X4",
        "outputId": "ec0c671b-35ba-4317-d8d9-94c354760999"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 209/209 [00:05<00:00, 39.86it/s]\n",
            "100%|██████████| 209/209 [00:04<00:00, 50.68it/s]\n",
            "100%|██████████| 209/209 [00:04<00:00, 45.81it/s]\n",
            "100%|██████████| 209/209 [00:04<00:00, 47.92it/s]\n",
            "100%|██████████| 209/209 [00:04<00:00, 48.80it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.mean(acc_trs)*100, np.std(acc_trs)*100)\n",
        "print(np.mean(acc_tes)*100, np.std(acc_tes)*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nne15YNQCIzo",
        "outputId": "30e8bbdb-3dbc-49af-94c2-1c9b17ff176d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "94.98999953269958 0.36118669944977455\n",
            "94.36199903488159 0.4591886793352151\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rQdY4frEDKsn"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Zp7SDQtQ6HKm",
        "qU_peqZP6L7l",
        "rmQ2jF0l6rhn",
        "W-zcwWb07ir0"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
