{"cells":[{"cell_type":"markdown","source":["# CIFAR-10 Classification"],"metadata":{"id":"TmtU86FNyA9Y"}},{"cell_type":"markdown","metadata":{"id":"o6ggqZMmDADM"},"source":["# Import"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lTK0TcQXC1yB","outputId":"b92f8c1d-093c-4a2c-ebe3-fcf8f09f55f2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Using cpu\n"]}],"source":["import matplotlib.pyplot as plt\n","import torch\n","import torch.nn.functional as F\n","import torchvision\n","import torchvision.transforms as transforms\n","from tqdm import tqdm\n","from torch.optim import Adam, SGD\n","from torchvision.datasets import CIFAR10\n","from torchvision.transforms import Compose, ToTensor, Normalize, Lambda\n","from torch.utils.data import DataLoader\n","\n","import numpy as np\n","import random\n","import math\n","\n","from sklearn.manifold import TSNE\n","import time\n","\n","import altair as alt\n","alt.data_transformers.disable_max_rows()\n","import pandas as pd\n","GPU = True # Choose whether to use GPU\n","if GPU:\n","    device = torch.device(\"cuda\"  if torch.cuda.is_available() else \"cpu\")\n","else:\n","    device = torch.device(\"cpu\")\n","print(f'Using {device}')"]},{"cell_type":"markdown","metadata":{"id":"rGU9NjcZYmWq"},"source":["# Network"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"giRe2tGRVSMg"},"outputs":[],"source":["class MFAN(torch.nn.Module):\n","    def __init__(self,\n","                 x_in, x_lr,\n","                 y_in, y_lr, d_lr,\n","                 hid_dims,# 500, 300, 300\n","                 num_epoch=1, num_epoch_D=300,\n","                 d_loss_func=torch.nn.CrossEntropyLoss(),\n","                 enc_ABC=[1,1,1]):\n","        super(MFAN, self).__init__()\n","        self.x_net = torch.nn.Sequential( torch.nn.Linear(x_in, hid_dims[0]) ).to(device) # 784_500\n","        self.y_net = torch.nn.Sequential( torch.nn.Linear(y_in, hid_dims[0]) ).to(device) # 784_500\n","        self.d_net = torch.nn.Sequential( torch.nn.Linear(hid_dims[0], y_in) ).to(device) # 500_10\n","        for i in range(len(hid_dims)-1):\n","            self.x_net.append( torch.nn.Linear( hid_dims[i], hid_dims[i+1]) ).to(device)\n","            self.y_net.append( torch.nn.Linear( hid_dims[i], hid_dims[i+1]) ).to(device)\n","            self.d_net.append( torch.nn.Linear( hid_dims[i+1], y_in) ).to(device)\n","        self.relu = torch.nn.ReLU()\n","\n","        # optimizers\n","        self.x_opt = Adam(self.x_net.parameters(), lr=x_lr)\n","        self.y_opt = Adam(self.y_net.parameters(), lr=y_lr)\n","        self.d_opt = Adam(self.d_net.parameters(), lr=d_lr)\n","\n","        self.d_loss_func = d_loss_func\n","\n","        # train iter\n","        self.num_epoch = num_epoch\n","        # self.batch_size = batch\n","        self.num_epoch_D = num_epoch_D\n","\n","        self.A, self.B, self.C= enc_ABC\n","\n","    def forward(self, x, y_pos, y_neg, layer_ind):\n","        Zx = self.x_net[layer_ind]( x ) # [60000, 500]\n","        Zys = self.y_net[layer_ind]( torch.cat([y_neg, y_pos],0) ) # [120000, 500]\n","        Zy_neg, Zy_pos = Zys[:len(y_neg)], Zys[len(y_pos):] # [60000, 500], [60000, 500]\n","        pos_sim = F.cosine_similarity(Zx, Zy_pos, dim=1) * self.A\n","        neg_sim = F.cosine_similarity(Zx, Zy_neg, dim=1) * self.B\n","\n","        y_neg_similarity = F.cosine_similarity(Zy_neg, Zy_pos, dim=1) * self.C\n","        loss = (- pos_sim + neg_sim + y_neg_similarity).mean()\n","        # loss = (- pos_sim + neg_sim).mean()\n","        self.x_opt.zero_grad()\n","        self.y_opt.zero_grad()\n","        loss.backward()\n","        self.x_opt.step()\n","        self.y_opt.step()\n","        return Zx, Zy_pos, Zy_neg, loss.item()\n","\n","    def d_forward(self, Zx, true_y_pos, layer_ind):\n","        y_pred = self.d_net[layer_ind]( Zx )\n","        loss = self.d_loss_func(y_pred, true_y_pos)\n","        self.d_opt.zero_grad()\n","        loss.backward()\n","        self.d_opt.step()\n","        return y_pred, loss.item()"]},{"cell_type":"markdown","metadata":{"id":"ppvqT2UKag4v"},"source":["# Init_loaders"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1ybqX59MamX2","colab":{"base_uri":"https://localhost:8080/"},"outputId":"cff0fbcb-b303-4555-e0e7-b88e34c36083"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 170M/170M [00:03<00:00, 55.3MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Extracting ./data/cifar-10-python.tar.gz to ./data\n","Files already downloaded and verified\n"]}],"source":["transform = transforms.Compose(\n","    [transforms.ToTensor(),\n","     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n","     Lambda(lambda x: torch.flatten(x))])\n","\n","batch_size = 50000\n","test_batch_size = 10000\n","\n","trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n","                                        download=True, transform=transform)\n","train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n","                                          shuffle=True)\n","\n","testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n","                                       download=True, transform=transform)\n","test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n","                                         shuffle=False)\n","\n","classes = ('plane', 'car', 'bird', 'cat',\n","           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"]},{"cell_type":"code","source":["def _load():\n","    x_tr, y_tr = next(iter(train_loader))\n","    x_tr, y_true = x_tr.to(device), y_tr.to(device)\n","\n","    x_te, y_te = next(iter(test_loader))\n","    x_te, y_te = x_te.to(device), y_te.to(device)\n","\n","    y_tr = F.one_hot(y_true).float().to(device)\n","    return x_tr, y_tr, x_te, y_te, y_true"],"metadata":{"id":"RAI6nILKeLOd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# playMFAN()"],"metadata":{"id":"Hub1Z-XFrCED"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"wnNdm7YippN2"},"outputs":[],"source":["def playMFAN(lr_x=1e-5, lr_y=1e-2, lr_d=1e-2, dim=[64, 32, 32],ABC=[0.6,0.3,0.6],EB=64,DB=64,EE=30,DE=64):\n","    x_tr, y_tr, x_te, y_te, y_true = _load()\n","\n","    model = MFAN(x_tr.shape[1], 1e-5,\n","                10, 1e-2, 1e-2,\n","                dim,\n","                enc_ABC=ABC)\n","    num_classes = 10\n","    batch_size = EB\n","    dec_batch_size = DB\n","    num_epoch = EE\n","    d_num_epoch = DE\n","\n","    x = x_tr.clone().to(device)\n","    y_pos = y_tr.clone().to(device)\n","    y_tr_neg = (y_true.cpu() + np.random.randint(1, num_classes, len(y_true))) % num_classes\n","    y_neg = F.one_hot(y_tr_neg).float().to(device)\n","\n","    loss_dict = {'encoder':[], 'decoder':[]}\n","    # Start Train MFAN\n","    MFAN_start_time = time.time()\n","    model.train()\n","    Zx_layers_tr = [] # store for Decoder training\n","    # ----------------------- Encoder ---------------------------\n","    iter_batch = x.shape[0]//batch_size\n","    for li in range(len(model.x_net)):\n","        losses = []\n","        Zx_layer_data_tr = []\n","        for _ni in range(num_epoch):\n","        # for _ni in tqdm(range(num_epoch),\n","        #                 desc='Encode '+str(li+1)+'/'+str(len(model.x_net))+' layer; num_iter_batch='+str(iter_batch)):\n","            Zx, Zy_pos, Zy_neg = [], [], []\n","            for i in range(x.shape[0]//batch_size):\n","                start_i = i * batch_size\n","                end_i = start_i + batch_size\n","                xb, y_posb, y_negb = x[start_i:end_i], y_pos[start_i:end_i], y_neg[start_i:end_i]\n","                Zxb, Zy_posb, Zy_negb, _loss = model.forward(xb, y_posb, y_negb, li)\n","                losses.append(_loss)\n","                if Zx == []:\n","                    Zx, Zy_pos, Zy_neg = Zxb, Zy_posb, Zy_negb\n","                else:\n","                    Zx, Zy_pos, Zy_neg = torch.cat((Zx,Zxb),0), torch.cat((Zy_pos,Zy_posb),0), torch.cat((Zy_neg,Zy_negb),0)\n","            Zx_layer_data_tr = Zx.detach() # use only the last n_epoch's Zx to train decoder\n","        Zx_layers_tr.append(Zx_layer_data_tr)\n","        loss_dict['encoder'].append(losses)\n","        x, y_pos, y_neg = model.relu(F.normalize(Zx)).detach(), model.relu(F.normalize(Zy_pos)).detach(), model.relu(F.normalize(Zy_neg)).detach()\n","    # ----------------------- Decoder ---------------------------\n","    iter_batch = Zx_layers_tr[0].shape[0]//dec_batch_size\n","    for li in range(len(model.x_net)):\n","        losses = []\n","        for _ni in range(d_num_epoch):\n","        # for _ni in tqdm(range(d_num_epoch),\n","        #                 desc='Decode '+str(li+1)+'/'+str(len(model.x_net))+' layer; num_iter_batch='+str(iter_batch)):\n","            Zx_tr = Zx_layers_tr[li]\n","            y_pos = F.one_hot(y_true).float().to(device)\n","            for i in range(Zx_tr.shape[0]//dec_batch_size):\n","                start_i = i * dec_batch_size\n","                end_i = start_i + dec_batch_size\n","                Zx_trb, y_posb = Zx_tr[start_i:end_i], y_pos[start_i:end_i]\n","                y_predb, _loss = model.d_forward(Zx_trb, y_posb, li)\n","                losses.append(_loss)\n","        loss_dict['decoder'].append(losses)\n","    print()\n","    print(\"MFAN Train: --- %s seconds ---\" % (time.time() - MFAN_start_time))\n","    # =========================== EVAL Accuracy ====================================\n","    y_tr_eval = y_tr.clone().to(device)\n","    y_te_eval = y_te.clone().to(device)\n","    x_tr_eval = x_tr.clone().to(device)\n","    x_te_eval = x_te.clone().to(device)\n","\n","    MFAN_start_time = time.time()\n","    model.eval()\n","\n","    acc_tr = [] # store train accuracy\n","    acc_te = [] # store test accuracy\n","    for i in range(len(model.d_net)):\n","        with torch.no_grad():\n","            Zx_tr_eval = model.x_net[i](x_tr_eval)\n","            y_pred_tr = model.d_net[i](Zx_tr_eval)\n","            # acc_tr.append((torch.argmax(y_pred_tr, dim=1) == y_tr_eval).sum().item() / y_tr_eval.size(0)) # Convert logits to labels\n","            acc_tr.append((torch.argmax(y_pred_tr, dim=1) == torch.argmax(y_tr, dim=1)).sum().item() / y_tr.size(0)) # Convert logits to labels\n","\n","            x_tr_eval = model.relu(F.normalize(Zx_tr_eval)).detach()\n","\n","            Zx_te_eval = model.x_net[i](x_te_eval)\n","            y_pred_te = model.d_net[i](Zx_te_eval)\n","            # acc_te.append((torch.argmax(y_pred_te, dim=1) == y_te_eval).sum().item() / y_te_eval.size(0)) # Convert logits to labels\n","            acc_te.append((torch.argmax(y_pred_te, dim=1) == y_te).sum().item() / y_te.size(0)) # Convert logits to labels\n","\n","            x_te_eval = model.relu(F.normalize(Zx_te_eval)).detach()\n","    print(\"MFAN Eval: --- %s seconds ---\" % (time.time() - MFAN_start_time))\n","    print('acc: tr',acc_tr,' te',acc_te)"]},{"cell_type":"code","source":["playMFAN(\n","    dim=[256, 128, 64],\n","    ABC=[0.6,0.4,0.6],\n","    EB=256,DB=256,\n","    EE=1,DE=5,\n","    lr_x=1e-2, lr_y=1e-3, lr_d=1e-2)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XBzAcisvexch","outputId":"5f564236-2182-43a1-f24a-f05082153d54"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","MFAN Train: --- 29.704814195632935 seconds ---\n","MFAN Eval: --- 2.272536277770996 seconds ---\n","acc: tr [0.3977, 0.3327, 0.2776]  te [0.3775, 0.3277, 0.2757]\n"]}]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}